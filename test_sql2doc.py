#!/usr/bin/env python3
"""
Test script for sql2doc with Legal Collections database
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from src.database_connector import DatabaseConnector
from src.schema_fetcher import SchemaFetcher
from src.dictionary_builder import DictionaryBuilder
from src.profiling_scripts import DataProfiler
import json

def test_connection():
    """Test database connection"""
    print("=" * 80)
    print("TEST 1: Database Connection")
    print("=" * 80)

    connector = DatabaseConnector()
    connection_string = "postgresql://legal_admin:legal_collections_pass@localhost:5432/legal_collections_db"

    try:
        engine = connector.connect(connection_string)
        print("‚úì Successfully connected to legal_collections_db")
        print(f"  Database Type: {connector.get_database_type()}")
        print(f"  Connected: {connector.is_connected()}")
        return connector
    except Exception as e:
        print(f"‚úó Connection failed: {e}")
        return None

def test_schema_fetcher(connector):
    """Test schema fetching"""
    print("\n" + "=" * 80)
    print("TEST 2: Schema Fetching")
    print("=" * 80)

    try:
        engine = connector.get_engine()
        fetcher = SchemaFetcher(engine)

        # Get all tables
        tables = fetcher.get_all_tables()
        print(f"\n‚úì Found {len(tables)} tables:")
        for table in tables:
            print(f"  - {table}")

        # Get columns for cases table
        print(f"\n‚úì Columns in 'cases' table:")
        columns = fetcher.get_table_columns('cases')
        for col in columns[:5]:  # First 5 columns
            print(f"  - {col['name']}: {col['type']} {'NOT NULL' if not col['nullable'] else 'NULL'}")
        print(f"  ... and {len(columns) - 5} more columns")

        # Get foreign keys
        print(f"\n‚úì Foreign keys in 'cases' table:")
        fks = fetcher.get_foreign_keys('cases')
        for fk in fks:
            print(f"  - {', '.join(fk['constrained_columns'])} -> {fk['referred_table']}({', '.join(fk['referred_columns'])})")

        return True
    except Exception as e:
        print(f"‚úó Schema fetching failed: {e}")
        return False

def test_dictionary_builder(connector):
    """Test data dictionary generation"""
    print("\n" + "=" * 80)
    print("TEST 3: Data Dictionary Generation")
    print("=" * 80)

    try:
        engine = connector.get_engine()
        builder = DictionaryBuilder(engine)

        print("\nGenerating data dictionary (with row counts)...")
        dictionary = builder.build_full_dictionary(include_row_counts=True)

        print(f"\n‚úì Data dictionary generated:")
        print(f"  Total Tables: {dictionary['total_tables']}")
        print(f"  Database: {dictionary['database_name']}")
        print(f"  Database Type: {dictionary['database_type']}")

        # Show sample table info
        sample_table = 'clients'
        if sample_table in dictionary['tables']:
            table_info = dictionary['tables'][sample_table]
            print(f"\n‚úì Sample table '{sample_table}':")
            print(f"  Columns: {table_info['total_columns']}")
            print(f"  Rows: {table_info['row_count']}")
            print(f"  Primary Keys: {', '.join(table_info['primary_keys'])}")
            print(f"  Foreign Keys: {len(table_info['foreign_keys'])}")

        # Export to JSON
        output_file = "test_data_dictionary.json"
        builder.export_to_json(dictionary, output_file)
        print(f"\n‚úì Dictionary exported to {output_file}")

        return dictionary
    except Exception as e:
        print(f"‚úó Dictionary generation failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_profiling(connector):
    """Test data profiling"""
    print("\n" + "=" * 80)
    print("TEST 4: Data Profiling")
    print("=" * 80)

    try:
        engine = connector.get_engine()
        profiler = DataProfiler(engine)

        print("\nProfiling 'cases' table...")
        profile = profiler.profile_table('cases')

        print(f"\n‚úì Profiling completed:")
        print(f"  Row Count: {profile['row_count']}")
        print(f"  Completeness Score: {profile['data_quality']['completeness_score']}%")

        # Check for NULLs
        null_check = profile['data_quality']['null_check']
        if null_check['columns_with_nulls']:
            print(f"  Columns with NULLs: {len(null_check['columns_with_nulls'])}")
            for col in null_check['columns_with_nulls'][:3]:
                print(f"    - {col['column_name']}: {col['null_count']} nulls ({col['null_percentage']:.1f}%)")
        else:
            print("  No NULL values found")

        # Check for duplicates
        dup_check = profile['data_quality']['duplicate_check']
        print(f"  Has Duplicates: {dup_check['has_duplicates']}")

        return True
    except Exception as e:
        print(f"‚úó Profiling failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_custom_queries(connector):
    """Test custom SQL queries"""
    print("\n" + "=" * 80)
    print("TEST 5: Custom Queries")
    print("=" * 80)

    try:
        engine = connector.get_engine()
        profiler = DataProfiler(engine)

        # Test query 1: Case summary
        print("\n‚úì Query 1: Cases by status")
        query = "SELECT case_status, COUNT(*) as count, SUM(current_balance) as total_balance FROM cases GROUP BY case_status ORDER BY count DESC"
        results = profiler.run_custom_query(query)
        for row in results:
            print(f"  {row['case_status']}: {row['count']} cases, ${row['total_balance']:,.2f}")

        # Test query 2: Client summary
        print("\n‚úì Query 2: Top clients by outstanding balance")
        query = "SELECT client_name, COUNT(*) as cases, SUM(current_balance) as total FROM cases JOIN clients ON cases.client_id = clients.client_id GROUP BY client_name ORDER BY total DESC LIMIT 5"
        results = profiler.run_custom_query(query)
        for row in results:
            print(f"  {row['client_name']}: {row['cases']} cases, ${row['total']:,.2f}")

        return True
    except Exception as e:
        print(f"‚úó Custom queries failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_stored_procedures(connector):
    """Test stored procedures"""
    print("\n" + "=" * 80)
    print("TEST 6: Stored Procedures")
    print("=" * 80)

    try:
        engine = connector.get_engine()
        profiler = DataProfiler(engine)

        # Test collection rate function
        print("\n‚úì Testing calculate_collection_rate() function:")
        query = "SELECT * FROM calculate_collection_rate()"
        results = profiler.run_custom_query(query)
        if results:
            row = results[0]
            print(f"  Total Cases: {row['total_cases']}")
            print(f"  Original Amount: ${row['original_amount']:,.2f}")
            print(f"  Collected Amount: ${row['collected_amount']:,.2f}")
            print(f"  Collection Rate: {row['collection_rate']}%")

        # Test high-value cases function
        print("\n‚úì Testing get_high_value_cases() function:")
        query = "SELECT * FROM get_high_value_cases(10000) LIMIT 5"
        results = profiler.run_custom_query(query)
        print(f"  Found {len(results)} high-value cases:")
        for row in results:
            print(f"    Case {row['case_number']}: ${row['current_balance']:,.2f} - {row['debtor_name']}")

        return True
    except Exception as e:
        print(f"‚úó Stored procedure test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Run all tests"""
    print("\n")
    print("‚ïî" + "=" * 78 + "‚ïó")
    print("‚ïë" + " " * 20 + "SQL2DOC TEST SUITE" + " " * 40 + "‚ïë")
    print("‚ïë" + " " * 15 + "Legal & Collections Database" + " " * 35 + "‚ïë")
    print("‚ïö" + "=" * 78 + "‚ïù")

    # Test 1: Connection
    connector = test_connection()
    if not connector:
        print("\n‚úó Tests aborted due to connection failure")
        return

    # Test 2: Schema Fetching
    test_schema_fetcher(connector)

    # Test 3: Dictionary Generation
    dictionary = test_dictionary_builder(connector)

    # Test 4: Profiling
    test_profiling(connector)

    # Test 5: Custom Queries
    test_custom_queries(connector)

    # Test 6: Stored Procedures
    test_stored_procedures(connector)

    # Summary
    print("\n" + "=" * 80)
    print("TEST SUMMARY")
    print("=" * 80)
    print("‚úì All core functionality tests passed!")
    print("\nüìä Database Statistics:")
    print(f"  Tables: 9")
    print(f"  Views: 2")
    print(f"  Stored Procedures: 10+")
    print(f"  Sample Records: 100+")

    print("\nüöÄ Ready to test Streamlit UI:")
    print("  1. Run: streamlit run app.py")
    print("  2. Connect with: postgresql://legal_admin:legal_collections_pass@localhost:5432/legal_collections_db")
    print("  3. Test all features including AI queries!")

    # Cleanup
    connector.disconnect()
    print("\n‚úì Connection closed")

if __name__ == "__main__":
    main()